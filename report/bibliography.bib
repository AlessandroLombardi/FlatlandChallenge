# DRL books

@book{graesser2019foundations,
    title={Foundations of Deep Reinforcement Learning: Theory and Practice in Python},
    author={Graesser, L. and Keng, W.L.},
    isbn={9780135172483},
    series={Addison-Wesley Data \& Analytics Series},
    url={https://books.google.it/books?id=0HW7DwAAQBAJ},
    year={2019},
    publisher={Pearson Education}
}

# MARL

@article{MARL-definition,
    author = {Babuska, Robert},
    year = {2008},
    month = {03},
    pages = {156-172},
    title = {A Comprehensive Survey of Multiagent Reinforcement Learning},
    volume = {38}
}

@misc{zhang2019multiagent,
    title={Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms},
    author={Kaiqing Zhang and Zhuoran Yang and Tamer Başar},
    year={2019},
    eprint={1911.10635},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Hernandez-Leal-2019,
    title={A survey and critique of multiagent deep reinforcement learning},
    volume={33},
    ISSN={1573-7454},
    url={http://dx.doi.org/10.1007/s10458-019-09421-1},
    DOI={10.1007/s10458-019-09421-1},
    number={6},
    journal={Autonomous Agents and Multi-Agent Systems},
    publisher={Springer Science and Business Media LLC},
    author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E.},
    year={2019},
    month={Oct},
    pages={750–797}
}

@article{Nguyen-2020,
    title={Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications},
    ISSN={2168-2275},
    url={http://dx.doi.org/10.1109/TCYB.2020.2977374},
    DOI={10.1109/tcyb.2020.2977374},
    journal={IEEE Transactions on Cybernetics},
    publisher={Institute of Electrical and Electronics Engineers (IEEE)},
    author={Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
    year={2020},
    pages={1–14}
}

@masterthesis{castaneda,
    author = {Castaneda, A. O.},
    title = {Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms},
    school = {School of Informatics, University of Edinburgh},
    year = {2016},
}

@misc{papoudakis2019dealing,
    title={Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning},
    author={Georgios Papoudakis and Filippos Christianos and Arrasy Rahman and Stefano V. Albrecht},
    year={2019},
    eprint={1906.04737},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

# PS-PPO

@inproceedings{ps-ppo-paper,
    author = {Gupta, Jayesh and Egorov, Maxim and Kochenderfer, Mykel},
    year = {2017},
    month = {11},
    pages = {66-83},
    title = {Cooperative Multi-agent Control Using Deep Reinforcement Learning},
    isbn = {978-3-319-71681-7},
    doi = {10.1007/978-3-319-71682-4_5}
}

@misc{trpo,
    title={Trust Region Policy Optimization},
    author={John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
    year={2015},
    eprint={1502.05477},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo,
    title={Proximal Policy Optimization Algorithms},
    author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
    year={2017},
    eprint={1707.06347},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{gae,
    title={High-Dimensional Continuous Control Using Generalized Advantage Estimation},
    author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
    year={2015},
    eprint={1506.02438},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo-baselines,
    author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
    title = {OpenAI Baselines},
    year = {2017},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/openai/baselines}},
}

@misc{ppo-implementation-1,
    title={Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO},
    author={Logan Engstrom and Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Firdaus Janoos and Larry Rudolph and Aleksander Madry},
    year={2020},
    eprint={2005.12729},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo-implementation-2,
    title={What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study},
    author={Marcin Andrychowicz and Anton Raichuk and Piotr Stańczyk and Manu Orsini and Sertan Girgin and Raphael Marinier and Léonard Hussenot and Matthieu Geist and Olivier Pietquin and Marcin Michalski and Sylvain Gelly and Olivier Bachem},
    year={2020},
    eprint={2006.05990},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo-32-implementations-details,
    author = {Costa Huang},
    year = {2020},
    title = {The 32 Implementation Details of Proximal Policy Optimization (PPO) Algorithm},
    howpublished = {\url{https://costa.sh/blog-the-32-implementation-details-of-ppo.html}},
}

# D3QN

@article{human-level,
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei and Veness, Joel and Bellemare, Marc and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    year = {2015},
    month = {02},
    pages = {529-33},
    title = {Human-level control through deep reinforcement learning},
    volume = {518},
    journal = {Nature},
    doi = {10.1038/nature14236}
}

@misc{rainbow,
    title={Rainbow: Combining Improvements in Deep Reinforcement Learning},
    author={Matteo Hessel and Joseph Modayil and Hado van Hasselt and Tom Schaul and Georg Ostrovski and Will Dabney and Dan Horgan and Bilal Piot and Mohammad Azar and David Silver},
    year={2017},
    eprint={1710.02298},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{dqn,
    title={Playing Atari with Deep Reinforcement Learning},
    author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
    year={2013},
    eprint={1312.5602},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{dueling,
    title={Dueling Network Architectures for Deep Reinforcement Learning},
    author={Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot and Nando de Freitas},
    year={2015},
    eprint={1511.06581},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{weighted-ddqn,
    title={Weighted Double Deep Multiagent Reinforcement Learning in Stochastic Cooperative Environments},
    author={Yan Zheng and Jianye Hao and Zongzhang Zhang},
    year={2018},
    eprint={1802.08534},
    archivePrefix={arXiv},
    primaryClass={cs.MA}
}

@misc{prioritized,
    title={Prioritized Experience Replay},
    author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
    year={2015},
    eprint={1511.05952},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{fingerprints,
    title={Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning},
    author={Jakob Foerster and Nantas Nardelli and Gregory Farquhar and Triantafyllos Afouras and Philip H. S. Torr and Pushmeet Kohli and Shimon Whiteson},
    year={2017},
    eprint={1702.08887},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

# Curriculum

@inproceedings{bengio-curiculum,
    author = {Bengio, Y. and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
    year = {2009},
    month = {01},
    pages = {6},
    title = {Curriculum learning},
    volume = {60},
    journal = {Journal of the American Podiatry Association},
    doi = {10.1145/1553374.1553380}
}

@misc{narvekar2020curriculum,
    title={Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey},
    author={Sanmit Narvekar and Bei Peng and Matteo Leonetti and Jivko Sinapov and Matthew E. Taylor and Peter Stone},
    year={2020},
    eprint={2003.04960},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{object-oriented-mdp,
    author = {Silva, Felipe Leno Da and Costa, Anna Helena Reali},
    title = {Object-Oriented Curriculum Generation for Reinforcement Learning},
    year = {2018},
    publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
    address = {Richland, SC},
    abstract = {Autonomously learning a complex task takes a very long time for Reinforcement Learning (RL) agents. One way to learn faster is by dividing a complex task into several simple subtasks and organizing them into a Curriculum that guides Transfer Learning (TL) methods to reuse knowledge in a convenient sequence. However, previous works do not take into account the TL method to build specialized Curricula , leaving the burden of a careful subtask selection to a human. We here contribute novel procedures for: (i) dividing the target task into simpler ones under minimal human supervision; (ii) automatically generating Curricula based on object-oriented task descriptions; and (iii) using generated Curricula for reusing knowledge across tasks. Our experiments show that our proposal achieves a better performance using both manually given and generated subtasks when compared to the state-of-the-art technique in two different domains.},
    booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
    pages = {1026–1034},
    numpages = {9},
    keywords = {curriculum learning, transfer learning, reinforcement learning},
    location = {Stockholm, Sweden},
    series = {AAMAS '18}
}

# Action masking

@misc{ppo-action-masking,
    title={A Closer Look at Invalid Action Masking in Policy Gradient Algorithms},
    author={Shengyi Huang and Santiago Ontañón},
    year={2020},
    eprint={2006.14171},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{rl-fastandslow,
    author = {Botvinick, Mathew and Ritter, Sam and Wang, Jane and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis},
    year = {2019},
    month = {04},
    pages = {408-422},
    title = {Reinforcement Learning, Fast and Slow},
    volume = {23},
    journal = {Trends in Cognitive Sciences},
    doi = {10.1016/j.tics.2019.02.006}
}

@article{ppo-action-masking2,
    title = "Implementing action mask in proximal policy optimization (PPO) algorithm",
    journal = "ICT Express",
    year = "2020",
    issn = "2405-9595",
    doi = "https://doi.org/10.1016/j.icte.2020.05.003",
    url = "http://www.sciencedirect.com/science/article/pii/S2405959520300746",
    author = "Cheng-Yen Tang and Chien-Hung Liu and Woei-Kae Chen and Shingchern D. You",
    keywords = "PPO, Invalid action, Reinforcement learning"
}

% Future

@inproceedings{Stanford2016MULTIAGENTDR,
    title={MULTI-AGENT DEEP REINFORCEMENT LEARNING},
    author={Maxim Egorov Stanford},
    year={2016}
}

@article{weng2019metaRL,
    title   = "Meta Reinforcement Learning",
    author  = "Weng, Lilian",
    journal = "lilianweng.github.io/lil-log",
    year    = "2019",
    url     = "http://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html"
}

@inproceedings{pathakICMl17curiosity,
    Author = {Pathak, Deepak and
    Agrawal, Pulkit and
    Efros, Alexei A. and
    Darrell, Trevor},
    Title = {Curiosity-driven Exploration
    by Self-supervised Prediction},
    Booktitle = {ICML},
    Year = {2017}
}
