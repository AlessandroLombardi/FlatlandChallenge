# DRL books

@book{graesser2019foundations,
  title={Foundations of Deep Reinforcement Learning: Theory and Practice in Python},
  author={Graesser, L. and Keng, W.L.},
  isbn={9780135172483},
  series={Addison-Wesley Data \& Analytics Series},
  url={https://books.google.it/books?id=0HW7DwAAQBAJ},
  year={2019},
  publisher={Pearson Education}
}

# MARL

@article{MARL_definition,
   author = {Babuska, Robert},
   year = {2008},
   month = {03},
   pages = {156-172},
   title = {A Comprehensive Survey of Multiagent Reinforcement Learning},
   volume = {38}
}

@misc{zhang2019multiagent,
   title={Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms},
   author={Kaiqing Zhang and Zhuoran Yang and Tamer Başar},
   year={2019},
   eprint={1911.10635},
   archivePrefix={arXiv},
   primaryClass={cs.LG}
}

@article{Hernandez_Leal_2019,
   title={A survey and critique of multiagent deep reinforcement learning},
   volume={33},
   ISSN={1573-7454},
   url={http://dx.doi.org/10.1007/s10458-019-09421-1},
   DOI={10.1007/s10458-019-09421-1},
   number={6},
   journal={Autonomous Agents and Multi-Agent Systems},
   publisher={Springer Science and Business Media LLC},
   author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E.},
   year={2019},
   month={Oct},
   pages={750–797}
}

@article{Nguyen_2020,
   title={Deep Reinforcement Learning for Multiagent Systems: A Review of Challenges, Solutions, and Applications},
   ISSN={2168-2275},
   url={http://dx.doi.org/10.1109/TCYB.2020.2977374},
   DOI={10.1109/tcyb.2020.2977374},
   journal={IEEE Transactions on Cybernetics},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
   year={2020},
   pages={1–14}
}

@masterthesis{castaneda,
   author = {Castaneda, A. O.},
   title = {Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms},
   school = {School of Informatics, University of Edinburgh},
   year = {2016},
}

@misc{papoudakis2019dealing,
   title={Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning},
   author={Georgios Papoudakis and Filippos Christianos and Arrasy Rahman and Stefano V. Albrecht},
   year={2019},
   eprint={1906.04737},
   archivePrefix={arXiv},
   primaryClass={cs.LG}
}

# PS-PPO

@inproceedings{ps-ppo_paper,
   author = {Gupta, Jayesh and Egorov, Maxim and Kochenderfer, Mykel},
   year = {2017},
   month = {11},
   pages = {66-83},
   title = {Cooperative Multi-agent Control Using Deep Reinforcement Learning},
   isbn = {978-3-319-71681-7},
   doi = {10.1007/978-3-319-71682-4_5}
}

@misc{trpo,
    title={Trust Region Policy Optimization},
    author={John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
    year={2015},
    eprint={1502.05477},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo,
   title={Proximal Policy Optimization Algorithms},
   author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
   year={2017},
   eprint={1707.06347},
   archivePrefix={arXiv},
   primaryClass={cs.LG}
}

@misc{gae,
    title={High-Dimensional Continuous Control Using Generalized Advantage Estimation},
    author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
    year={2015},
    eprint={1506.02438},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo_baselines,
   title = {OpenAI PPO Baselines},
   howpublished = {\url{https://github.com/openai/baselines/tree/ea25b9e8b234e6ee1bca43083f8f3cf974143998/baselines/ppo2}}
}

@misc{ppo_implementation_1,
   title={Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO},
   author={Logan Engstrom and Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Firdaus Janoos and Larry Rudolph and Aleksander Madry},
   year={2020},
   eprint={2005.12729},
   archivePrefix={arXiv},
   primaryClass={cs.LG}
}

@misc{ppo_implementation_2,
    title={What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study},
    author={Marcin Andrychowicz and Anton Raichuk and Piotr Stańczyk and Manu Orsini and Sertan Girgin and Raphael Marinier and Léonard Hussenot and Matthieu Geist and Olivier Pietquin and Marcin Michalski and Sylvain Gelly and Olivier Bachem},
    year={2020},
    eprint={2006.05990},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ppo-32-implementations-details,
  title = {The 32 Implementation Details of Proximal Policy Optimization (PPO) Algorithm},
  howpublished = {\url{https://costa.sh/blog-the-32-implementation-details-of-ppo.html}},
}

# Action masking

@misc{ppo_action_masking,
    title={A Closer Look at Invalid Action Masking in Policy Gradient Algorithms},
    author={Shengyi Huang and Santiago Ontañón},
    year={2020},
    eprint={2006.14171},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{ppo_action_masking2,
    title = "Implementing action mask in proximal policy optimization (PPO) algorithm",
    journal = "ICT Express",
    year = "2020",
    issn = "2405-9595",
    doi = "https://doi.org/10.1016/j.icte.2020.05.003",
    url = "http://www.sciencedirect.com/science/article/pii/S2405959520300746",
    author = "Cheng-Yen Tang and Chien-Hung Liu and Woei-Kae Chen and Shingchern D. You",
    keywords = "PPO, Invalid action, Reinforcement learning"
}
